# author : caleb7023

import typing
import numpy as np

class NeuralNetwork:
    def __init__(self, layers:list=None, propatiy:list|str=None)->None:...
    def forward_propagation(self, input_data:np.ndarray)->np.ndarray:...
    def back_propagation(self, target:np.ndarray, learning_rate:float)->None:...
class ActivationFunction:
    def ident       (x:float)->float:...
    def sigmoid     (x:float)->float:...
    def hard_sigmoid(x:float)->float:...
    def log_sigmoid (x:float)->float:...
    def swish       (x:float)->float:...
    def mish        (x:float)->float:...
    def hard_swish  (x:float)->float:...
    def relu        (x:float)->float:...
    def relu6       (x:float)->float:...
    def leaky_relu  (x:float)->float:...
    def elu         (x:float)->float:...
    def tanh        (x:float)->float:...
    def tanh_shrink (x:float)->float:...
    def tanh_exp    (x:float)->float:...
    def hard_tanh   (x:float)->float:...
    def bent_ident  (x:float)->float:...
    def hard_shrink (x:float)->float:...
    def soft_shrink (x:float)->float:...
    class derivative:
        def ident       (x:float, y:float)->float:...
        def sigmoid     (x:float, y:float)->float:...
        def hard_sigmoid(x:float, y:float)->float:...
        def log_sigmoid (x:float, y:float)->float:...
        def swish       (x:float, y:float)->float:...
        def mish        (x:float, y:float)->float:...
        def hard_swish  (x:float, y:float)->float:...
        def relu        (x:float, y:float)->float:...
        def relu6       (x:float, y:float)->float:...
        def leaky_relu  (x:float, y:float)->float:...
        def elu         (x:float, y:float)->float:...
        def tanh        (x:float, y:float)->float:...
        def tanh_shrink (x:float, y:float)->float:...
        def tanh_exp    (x:float, y:float)->float:...
        def hard_tanh   (x:float, y:float)->float:...
        def bent_ident  (x:float, y:float)->float:...
        def hard_shrink (x:float, y:float)->float:...